"""DocumentSet-aware analysis pipeline.

Extends the base analysis pipeline to work with multi-document document sets.
"""

from __future__ import annotations

import logging
from typing import TYPE_CHECKING

from ..agent_runner import create_deepseek_agent
from ..agents.prompts import tender_analyzer
from ..api.client import BidSmartAPIClient
from ..state.project_state import BidProjectState
from ..tool_adapters import build_tender_analyzer_tools

if TYPE_CHECKING:
    from typing import Awaitable, Callable, Optional
    ProgressCallback = Optional[Callable[[str, str], Awaitable[None]]]

logger = logging.getLogger(__name__)


async def run_document_set_analysis_pipeline(
    project_id: str,
    api_url: str,
    progress_callback: ProgressCallback = None,
) -> dict:
    """Run tender document analysis on a document set.
    
    This pipeline:
    1. Analyzes primary document for key requirements
    2. Scans auxiliary documents for relevant context
    3. Cross-references historical bids for reusable content
    4. Generates comprehensive analysis report
    
    Args:
        project_id: The bid project ID
        api_url: Base URL of the BidSmart backend
        progress_callback: Async callback for progress updates
        
    Returns:
        Analysis report dictionary
    """
    # Initialize
    api_client = BidSmartAPIClient(api_url)
    state = BidProjectState()
    
    try:
        await state.load_from_backend(api_client, project_id)
        
        # Check if using document set
        if not state.is_using_document_set():
            logger.warning("No document set found, falling back to single document analysis")
            # Fall back to standard analysis
            from ..analysis_pipeline import run_analysis_pipeline
            return await run_analysis_pipeline(project_id, api_url, progress_callback)
        
        if progress_callback:
            await progress_callback("init", f"å¼€å§‹åˆ†ææ–‡æ¡£é›†: {state.document_set.name}")
        
        # Build tools
        analysis_tools = build_tender_analyzer_tools(state, api_client)
        
        # Create agent
        analyzer = create_deepseek_agent(
            name="document-set-analyzer",
            system_prompt=tender_analyzer.SYSTEM_PROMPT + _get_document_set_context(state),
            tools=analysis_tools,
            tool_call_limit=25,
        )
        
        # Build analysis instruction
        primary = state.document_set.get_primary_item()
        aux_count = len(state.document_set.get_items_by_role("auxiliary"))
        
        instruction = (
            f"è¯·æ·±åº¦åˆ†æé¡¹ç›® {project_id} çš„æ–‡æ¡£é›†ã€‚\n\n"
            f"æ–‡æ¡£é›†ä¿¡æ¯:\n"
            f"- åç§°: {state.document_set.name}\n"
            f"- ä¸»æ–‡æ¡£: {primary.name if primary else 'N/A'}\n"
            f"- è¾…åŠ©æ–‡æ¡£: {aux_count} ä¸ª\n\n"
            f"åˆ†ææ­¥éª¤:\n"
            f"1. é¦–å…ˆè°ƒç”¨ get_tender_tree è·å–ä¸»æ–‡æ¡£ç›®å½•ç»“æ„\n"
            f"2. ä½¿ç”¨ query_tender_requirements åˆ†æä¸»æ–‡æ¡£çš„å…³é”®ç« èŠ‚:\n"
            f"   - è¯„åˆ†æ ‡å‡†å’Œè¯„å®¡ç»†åˆ™\n"
            f"   - ä¾›åº”å•†é¡»çŸ¥é™„è¡¨\n"
            f"   - èµ„æ ¼è¦æ±‚\n"
            f"   - æŠ€æœ¯éœ€æ±‚\n"
            f"3. å¦‚å­˜åœ¨è¾…åŠ©æ–‡æ¡£ï¼Œå¯ç®€è¦æŸ¥çœ‹å…¶ç›®å½•ç»“æ„äº†è§£å†…å®¹ç±»å‹\n"
            f"4. ä½¿ç”¨ validate_scoring_criteria éªŒè¯è¯„åˆ†æ ‡å‡†\n"
            f"5. æœ€åè°ƒç”¨ save_analysis_report ä¿å­˜åˆ†ææŠ¥å‘Š\n\n"
            f"æ³¨æ„äº‹é¡¹:\n"
            f"- ä¸»æ–‡æ¡£æ˜¯åˆ†æé‡ç‚¹ï¼ŒåŒ…å«è¯„åˆ†æ ‡å‡†ç­‰å…³é”®ä¿¡æ¯\n"
            f"- è¾…åŠ©æ–‡æ¡£æä¾›è¡¥å……ä¿¡æ¯ï¼ŒæŒ‰éœ€æŸ¥è¯¢\n"
            f"- å¿…é¡»å¼•ç”¨åŸæ–‡ï¼Œä¸å¾—æ¦‚æ‹¬æˆ–æ¨æµ‹"
        )
        
        logger.info("Starting document set analysis for project %s", project_id)
        await analyzer.arun(instruction)
        
        if state.analysis_report:
            logger.info("Document set analysis complete: %d sections", 
                       len(state.analysis_report) - 1)
            if progress_callback:
                await progress_callback("complete", "æ–‡æ¡£é›†åˆ†æå®Œæˆ")
        
        return state.analysis_report or {}
        
    except Exception:
        logger.exception("Document set analysis pipeline failed for project %s", project_id)
        raise


def _get_document_set_context(state: BidProjectState) -> str:
    """Generate additional context for document set analysis.
    
    Args:
        state: Project state with document set
        
    Returns:
        Additional context text for system prompt
    """
    if not state.document_set:
        return ""
    
    doc_set = state.document_set
    primary = doc_set.get_primary_item()
    
    context = "\n\n## æ–‡æ¡£é›†ä¸Šä¸‹æ–‡\n\n"
    context += f"å½“å‰å·¥ä½œäºæ–‡æ¡£é›†: {doc_set.name}\n"
    context += f"åŒ…å« {len(doc_set)} ä¸ªæ–‡æ¡£:\n"
    
    for item in doc_set.get_sorted_items():
        icon = "â­" if item.role == "primary" else "ğŸ“„"
        context += f"{icon} [{item.doc_type}] {item.name}\n"
    
    context += "\n"
    context += "ä¸»æ–‡æ¡£æ˜¯æ‹›æ ‡è¦æ±‚çš„ä¸»è¦æ¥æºï¼Œè¾…åŠ©æ–‡æ¡£æä¾›å‚è€ƒèµ„æ–™ã€‚\n"
    context += "åˆ†ææ—¶ä»¥ä¸»æ–‡æ¡£ä¸ºä¸»ï¼Œå¿…è¦æ—¶æŸ¥é˜…è¾…åŠ©æ–‡æ¡£ã€‚\n"
    
    return context


async def run_document_set_outline_pipeline(
    project_id: str,
    api_url: str,
    progress_callback: ProgressCallback = None,
) -> list[dict]:
    """Generate outline considering document set structure.
    
    Args:
        project_id: Project ID
        api_url: API URL
        progress_callback: Progress callback
        
    Returns:
        List of section dictionaries
    """
    from ..outline_pipeline import run_outline_pipeline
    
    # For now, use standard outline pipeline
    # The document set context is already in state
    return await run_outline_pipeline(
        project_id=project_id,
        api_url=api_url,
        progress_callback=progress_callback,
    )


async def run_document_set_writing_pipeline(
    project_id: str,
    section_id: str,
    api_url: str,
    progress_callback: ProgressCallback = None,
) -> str:
    """Write a section using document set resources.
    
    This pipeline:
    1. Gets section requirements from primary document
    2. Searches auxiliary documents for reference content
    3. Looks for reusable content in historical bids
    4. Generates optimized content
    
    Args:
        project_id: Project ID
        section_id: Section ID to write
        api_url: API URL
        progress_callback: Progress callback
        
    Returns:
        Generated content
    """
    from ..content_pipeline import run_content_pipeline
    
    # Initialize
    api_client = BidSmartAPIClient(api_url)
    state = BidProjectState()
    await state.load_from_backend(api_client, project_id)
    
    if not state.is_using_document_set():
        # Standard writing
        return await run_content_pipeline(
            project_id=project_id,
            api_url=api_url,
            section_ids=[section_id],
            progress_callback=progress_callback,
        )
    
    # Document set aware writing
    if progress_callback:
        await progress_callback("init", f"å¼€å§‹ç¼–å†™ç« èŠ‚ï¼Œä½¿ç”¨æ–‡æ¡£é›†èµ„æº")
    
    # Get section info
    section = state.get_section(section_id)
    if not section:
        raise ValueError(f"Section {section_id} not found")
    
    # Check for historical bids in document set
    historical_items = state.document_set.get_items_by_type("historical")
    
    if historical_items and progress_callback:
        await progress_callback("reference", 
            f"å‘ç° {len(historical_items)} ä¸ªå†å²æ ‡ä¹¦å¯ä¾›å‚è€ƒ")
    
    # For now, use standard pipeline
    # Future enhancement: add historical bid content matching
    return await run_content_pipeline(
        project_id=project_id,
        api_url=api_url,
        section_ids=[section_id],
        progress_callback=progress_callback,
    )


async def run_document_set_full_pipeline(
    project_id: str,
    api_url: str,
    progress_callback: ProgressCallback = None,
) -> dict:
    """Run complete bid generation pipeline with document set support.
    
    Args:
        project_id: Project ID
        api_url: API URL
        progress_callback: Progress callback
        
    Returns:
        Final project summary
    """
    results = {
        "project_id": project_id,
        "analysis": None,
        "outline": None,
        "sections_written": 0,
        "errors": [],
    }
    
    try:
        # Phase 1: Analysis
        if progress_callback:
            await progress_callback("phase", "Phase 1: æ–‡æ¡£é›†åˆ†æ")
        
        analysis = await run_document_set_analysis_pipeline(
            project_id, api_url, progress_callback
        )
        results["analysis"] = analysis
        
        # Phase 2: Outline
        if progress_callback:
            await progress_callback("phase", "Phase 2: ç”Ÿæˆå¤§çº²")
        
        sections = await run_document_set_outline_pipeline(
            project_id, api_url, progress_callback
        )
        results["outline"] = sections
        
        # Phase 3: Writing (one section for demo)
        if progress_callback:
            await progress_callback("phase", "Phase 3: ç¼–å†™å†…å®¹")
        
        # Write first pending section
        api_client = BidSmartAPIClient(api_url)
        state = BidProjectState()
        await state.load_from_backend(api_client, project_id)
        
        pending = state.get_sections_by_status("pending")
        if pending:
            section = pending[0]
            await run_document_set_writing_pipeline(
                project_id, section["id"], api_url, progress_callback
            )
            results["sections_written"] = 1
        
        if progress_callback:
            await progress_callback("complete", "æ–‡æ¡£é›†æµç¨‹å®Œæˆ")
        
    except Exception as e:
        logger.exception("Full pipeline failed")
        results["errors"].append(str(e))
    
    return results
